{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py85-Cna3C-m"
      },
      "source": [
        "## HW2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f7BIE8HEAA0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1184a104-0219-4fee-e547-6baddbdb3353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE237Uh3ABKY",
        "outputId": "260cf454-59a9-4fc9-9f4b-9096dfff3db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# see more data augmentation https://pytorch.org/vision/stable/transforms.html\n",
        "mean = (0.5071, 0.4867, 0.4408)\n",
        "std = (0.2675, 0.2565, 0.2761)\n",
        "train_transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean, std)]) # calculte yourself\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean, std)]) # calculte yourself\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 100    # check\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_PDC78MUALYM"
      },
      "outputs": [],
      "source": [
        "class Toy_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzOoI9FCAiz3",
        "outputId": "1bf39e0f-5b07-4ad7-b4be-d2c23516fe5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# pick one\n",
        "\n",
        "# 1. model defined by yourself\n",
        "# model = Toy_CNN()        \n",
        "   \n",
        "# 2. off-the-shelf model\n",
        "# see https://pytorch.org/vision/stable/models.html\n",
        "# nn.Linear https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "model = models.resnet50(pretrained=True) \n",
        "model.fc = torch.nn.Linear(2048, num_classes)\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yxZ41jR1BT28"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001,\n",
        "                       weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_epoch = 20\n",
        "print_per_iteration = 100\n",
        "save_path = './model.pth'\n",
        "\n",
        "for epoch in range(total_epoch):  # loop over the dataset multiple times\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        if (i+1) % print_per_iteration == 0:    # print every 2000 mini-batches\n",
        "            print(f'[ep {epoch + 1}][{i + 1:5d}/{len(trainloader):5d}] loss: {loss.item():.3f}')\n",
        "    torch.save(model, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LTzbiubhyf2",
        "outputId": "6c0d5a84-ec16-45b0-afae-3c1382a397a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ep 1][  100/ 1563] loss: 4.228\n",
            "[ep 1][  200/ 1563] loss: 3.616\n",
            "[ep 1][  300/ 1563] loss: 2.834\n",
            "[ep 1][  400/ 1563] loss: 2.436\n",
            "[ep 1][  500/ 1563] loss: 2.567\n",
            "[ep 1][  600/ 1563] loss: 2.496\n",
            "[ep 1][  700/ 1563] loss: 1.693\n",
            "[ep 1][  800/ 1563] loss: 2.173\n",
            "[ep 1][  900/ 1563] loss: 2.765\n",
            "[ep 1][ 1000/ 1563] loss: 1.989\n",
            "[ep 1][ 1100/ 1563] loss: 2.112\n",
            "[ep 1][ 1200/ 1563] loss: 1.786\n",
            "[ep 1][ 1300/ 1563] loss: 1.884\n",
            "[ep 1][ 1400/ 1563] loss: 1.911\n",
            "[ep 1][ 1500/ 1563] loss: 2.160\n",
            "[ep 2][  100/ 1563] loss: 1.963\n",
            "[ep 2][  200/ 1563] loss: 1.661\n",
            "[ep 2][  300/ 1563] loss: 1.624\n",
            "[ep 2][  400/ 1563] loss: 1.945\n",
            "[ep 2][  500/ 1563] loss: 1.923\n",
            "[ep 2][  600/ 1563] loss: 1.458\n",
            "[ep 2][  700/ 1563] loss: 1.226\n",
            "[ep 2][  800/ 1563] loss: 1.394\n",
            "[ep 2][  900/ 1563] loss: 1.766\n",
            "[ep 2][ 1000/ 1563] loss: 2.060\n",
            "[ep 2][ 1100/ 1563] loss: 1.440\n",
            "[ep 2][ 1200/ 1563] loss: 1.364\n",
            "[ep 2][ 1300/ 1563] loss: 1.765\n",
            "[ep 2][ 1400/ 1563] loss: 1.629\n",
            "[ep 2][ 1500/ 1563] loss: 1.142\n",
            "[ep 3][  100/ 1563] loss: 1.779\n",
            "[ep 3][  200/ 1563] loss: 1.490\n",
            "[ep 3][  300/ 1563] loss: 1.915\n",
            "[ep 3][  400/ 1563] loss: 1.271\n",
            "[ep 3][  500/ 1563] loss: 0.936\n",
            "[ep 3][  600/ 1563] loss: 1.442\n",
            "[ep 3][  700/ 1563] loss: 1.789\n",
            "[ep 3][  800/ 1563] loss: 1.420\n",
            "[ep 3][  900/ 1563] loss: 1.851\n",
            "[ep 3][ 1000/ 1563] loss: 1.095\n",
            "[ep 3][ 1100/ 1563] loss: 1.796\n",
            "[ep 3][ 1200/ 1563] loss: 1.091\n",
            "[ep 3][ 1300/ 1563] loss: 1.962\n",
            "[ep 3][ 1400/ 1563] loss: 1.987\n",
            "[ep 3][ 1500/ 1563] loss: 1.673\n",
            "[ep 4][  100/ 1563] loss: 1.460\n",
            "[ep 4][  200/ 1563] loss: 0.980\n",
            "[ep 4][  300/ 1563] loss: 1.247\n",
            "[ep 4][  400/ 1563] loss: 1.120\n",
            "[ep 4][  500/ 1563] loss: 0.762\n",
            "[ep 4][  600/ 1563] loss: 0.871\n",
            "[ep 4][  700/ 1563] loss: 1.570\n",
            "[ep 4][  800/ 1563] loss: 1.264\n",
            "[ep 4][  900/ 1563] loss: 1.341\n",
            "[ep 4][ 1000/ 1563] loss: 1.236\n",
            "[ep 4][ 1100/ 1563] loss: 1.398\n",
            "[ep 4][ 1200/ 1563] loss: 1.646\n",
            "[ep 4][ 1300/ 1563] loss: 1.416\n",
            "[ep 4][ 1400/ 1563] loss: 1.387\n",
            "[ep 4][ 1500/ 1563] loss: 1.434\n",
            "[ep 5][  100/ 1563] loss: 1.134\n",
            "[ep 5][  200/ 1563] loss: 1.771\n",
            "[ep 5][  300/ 1563] loss: 1.109\n",
            "[ep 5][  400/ 1563] loss: 0.975\n",
            "[ep 5][  500/ 1563] loss: 0.919\n",
            "[ep 5][  600/ 1563] loss: 0.992\n",
            "[ep 5][  700/ 1563] loss: 1.637\n",
            "[ep 5][  800/ 1563] loss: 1.157\n",
            "[ep 5][  900/ 1563] loss: 1.351\n",
            "[ep 5][ 1000/ 1563] loss: 1.059\n",
            "[ep 5][ 1100/ 1563] loss: 1.084\n",
            "[ep 5][ 1200/ 1563] loss: 0.718\n",
            "[ep 5][ 1300/ 1563] loss: 0.697\n",
            "[ep 5][ 1400/ 1563] loss: 0.803\n",
            "[ep 5][ 1500/ 1563] loss: 1.198\n",
            "[ep 6][  100/ 1563] loss: 0.765\n",
            "[ep 6][  200/ 1563] loss: 1.012\n",
            "[ep 6][  300/ 1563] loss: 0.607\n",
            "[ep 6][  400/ 1563] loss: 0.472\n",
            "[ep 6][  500/ 1563] loss: 1.112\n",
            "[ep 6][  600/ 1563] loss: 1.098\n",
            "[ep 6][  700/ 1563] loss: 1.013\n",
            "[ep 6][  800/ 1563] loss: 1.215\n",
            "[ep 6][  900/ 1563] loss: 0.644\n",
            "[ep 6][ 1000/ 1563] loss: 0.670\n",
            "[ep 6][ 1100/ 1563] loss: 0.833\n",
            "[ep 6][ 1200/ 1563] loss: 0.916\n",
            "[ep 6][ 1300/ 1563] loss: 1.073\n",
            "[ep 6][ 1400/ 1563] loss: 1.015\n",
            "[ep 6][ 1500/ 1563] loss: 0.880\n",
            "[ep 7][  100/ 1563] loss: 0.786\n",
            "[ep 7][  200/ 1563] loss: 1.306\n",
            "[ep 7][  300/ 1563] loss: 0.378\n",
            "[ep 7][  400/ 1563] loss: 0.899\n",
            "[ep 7][  500/ 1563] loss: 0.833\n",
            "[ep 7][  600/ 1563] loss: 0.980\n",
            "[ep 7][  700/ 1563] loss: 0.462\n",
            "[ep 7][  800/ 1563] loss: 0.642\n",
            "[ep 7][  900/ 1563] loss: 0.736\n",
            "[ep 7][ 1000/ 1563] loss: 0.622\n",
            "[ep 7][ 1100/ 1563] loss: 0.684\n",
            "[ep 7][ 1200/ 1563] loss: 0.838\n",
            "[ep 7][ 1300/ 1563] loss: 1.054\n",
            "[ep 7][ 1400/ 1563] loss: 0.799\n",
            "[ep 7][ 1500/ 1563] loss: 0.791\n",
            "[ep 8][  100/ 1563] loss: 1.035\n",
            "[ep 8][  200/ 1563] loss: 0.579\n",
            "[ep 8][  300/ 1563] loss: 0.731\n",
            "[ep 8][  400/ 1563] loss: 0.655\n",
            "[ep 8][  500/ 1563] loss: 0.634\n",
            "[ep 8][  600/ 1563] loss: 0.747\n",
            "[ep 8][  700/ 1563] loss: 0.493\n",
            "[ep 8][  800/ 1563] loss: 0.356\n",
            "[ep 8][  900/ 1563] loss: 1.033\n",
            "[ep 8][ 1000/ 1563] loss: 0.840\n",
            "[ep 8][ 1100/ 1563] loss: 0.950\n",
            "[ep 8][ 1200/ 1563] loss: 0.596\n",
            "[ep 8][ 1300/ 1563] loss: 0.657\n",
            "[ep 8][ 1400/ 1563] loss: 0.565\n",
            "[ep 8][ 1500/ 1563] loss: 0.348\n",
            "[ep 9][  100/ 1563] loss: 0.550\n",
            "[ep 9][  200/ 1563] loss: 0.392\n",
            "[ep 9][  300/ 1563] loss: 0.654\n",
            "[ep 9][  400/ 1563] loss: 0.453\n",
            "[ep 9][  500/ 1563] loss: 0.608\n",
            "[ep 9][  600/ 1563] loss: 0.315\n",
            "[ep 9][  700/ 1563] loss: 0.896\n",
            "[ep 9][  800/ 1563] loss: 0.921\n",
            "[ep 9][  900/ 1563] loss: 0.513\n",
            "[ep 9][ 1000/ 1563] loss: 0.609\n",
            "[ep 9][ 1100/ 1563] loss: 0.508\n",
            "[ep 9][ 1200/ 1563] loss: 0.905\n",
            "[ep 9][ 1300/ 1563] loss: 0.450\n",
            "[ep 9][ 1400/ 1563] loss: 0.951\n",
            "[ep 9][ 1500/ 1563] loss: 0.745\n",
            "[ep 10][  100/ 1563] loss: 0.262\n",
            "[ep 10][  200/ 1563] loss: 0.416\n",
            "[ep 10][  300/ 1563] loss: 0.454\n",
            "[ep 10][  400/ 1563] loss: 0.761\n",
            "[ep 10][  500/ 1563] loss: 0.760\n",
            "[ep 10][  600/ 1563] loss: 0.769\n",
            "[ep 10][  700/ 1563] loss: 0.513\n",
            "[ep 10][  800/ 1563] loss: 1.011\n",
            "[ep 10][  900/ 1563] loss: 0.663\n",
            "[ep 10][ 1000/ 1563] loss: 0.821\n",
            "[ep 10][ 1100/ 1563] loss: 0.605\n",
            "[ep 10][ 1200/ 1563] loss: 0.395\n",
            "[ep 10][ 1300/ 1563] loss: 0.664\n",
            "[ep 10][ 1400/ 1563] loss: 0.551\n",
            "[ep 10][ 1500/ 1563] loss: 0.765\n",
            "[ep 11][  100/ 1563] loss: 0.161\n",
            "[ep 11][  200/ 1563] loss: 0.298\n",
            "[ep 11][  300/ 1563] loss: 0.355\n",
            "[ep 11][  400/ 1563] loss: 0.454\n",
            "[ep 11][  500/ 1563] loss: 0.802\n",
            "[ep 11][  600/ 1563] loss: 0.715\n",
            "[ep 11][  700/ 1563] loss: 0.734\n",
            "[ep 11][  800/ 1563] loss: 0.544\n",
            "[ep 11][  900/ 1563] loss: 0.607\n",
            "[ep 11][ 1000/ 1563] loss: 0.785\n",
            "[ep 11][ 1100/ 1563] loss: 0.658\n",
            "[ep 11][ 1200/ 1563] loss: 0.532\n",
            "[ep 11][ 1300/ 1563] loss: 0.417\n",
            "[ep 11][ 1400/ 1563] loss: 0.366\n",
            "[ep 11][ 1500/ 1563] loss: 0.449\n",
            "[ep 12][  100/ 1563] loss: 0.109\n",
            "[ep 12][  200/ 1563] loss: 0.169\n",
            "[ep 12][  300/ 1563] loss: 0.241\n",
            "[ep 12][  400/ 1563] loss: 0.314\n",
            "[ep 12][  500/ 1563] loss: 0.715\n",
            "[ep 12][  600/ 1563] loss: 0.595\n",
            "[ep 12][  700/ 1563] loss: 0.494\n",
            "[ep 12][  800/ 1563] loss: 0.422\n",
            "[ep 12][  900/ 1563] loss: 0.928\n",
            "[ep 12][ 1000/ 1563] loss: 0.356\n",
            "[ep 12][ 1100/ 1563] loss: 0.559\n",
            "[ep 12][ 1200/ 1563] loss: 0.484\n",
            "[ep 12][ 1300/ 1563] loss: 0.434\n",
            "[ep 12][ 1400/ 1563] loss: 0.227\n",
            "[ep 12][ 1500/ 1563] loss: 0.464\n",
            "[ep 13][  100/ 1563] loss: 0.311\n",
            "[ep 13][  200/ 1563] loss: 0.248\n",
            "[ep 13][  300/ 1563] loss: 0.113\n",
            "[ep 13][  400/ 1563] loss: 0.177\n",
            "[ep 13][  500/ 1563] loss: 0.483\n",
            "[ep 13][  600/ 1563] loss: 0.382\n",
            "[ep 13][  700/ 1563] loss: 0.483\n",
            "[ep 13][  800/ 1563] loss: 0.264\n",
            "[ep 13][  900/ 1563] loss: 0.310\n",
            "[ep 13][ 1000/ 1563] loss: 0.216\n",
            "[ep 13][ 1100/ 1563] loss: 0.876\n",
            "[ep 13][ 1200/ 1563] loss: 0.417\n",
            "[ep 13][ 1300/ 1563] loss: 0.622\n",
            "[ep 13][ 1400/ 1563] loss: 0.261\n",
            "[ep 13][ 1500/ 1563] loss: 0.557\n",
            "[ep 14][  100/ 1563] loss: 0.512\n",
            "[ep 14][  200/ 1563] loss: 0.353\n",
            "[ep 14][  300/ 1563] loss: 0.467\n",
            "[ep 14][  400/ 1563] loss: 0.439\n",
            "[ep 14][  500/ 1563] loss: 0.294\n",
            "[ep 14][  600/ 1563] loss: 0.526\n",
            "[ep 14][  700/ 1563] loss: 0.361\n",
            "[ep 14][  800/ 1563] loss: 0.401\n",
            "[ep 14][  900/ 1563] loss: 0.279\n",
            "[ep 14][ 1000/ 1563] loss: 0.420\n",
            "[ep 14][ 1100/ 1563] loss: 0.242\n",
            "[ep 14][ 1200/ 1563] loss: 0.340\n",
            "[ep 14][ 1300/ 1563] loss: 0.347\n",
            "[ep 14][ 1400/ 1563] loss: 0.435\n",
            "[ep 14][ 1500/ 1563] loss: 0.350\n",
            "[ep 15][  100/ 1563] loss: 0.148\n",
            "[ep 15][  200/ 1563] loss: 0.413\n",
            "[ep 15][  300/ 1563] loss: 0.213\n",
            "[ep 15][  400/ 1563] loss: 0.100\n",
            "[ep 15][  500/ 1563] loss: 0.229\n",
            "[ep 15][  600/ 1563] loss: 0.363\n",
            "[ep 15][  700/ 1563] loss: 0.306\n",
            "[ep 15][  800/ 1563] loss: 0.188\n",
            "[ep 15][  900/ 1563] loss: 0.155\n",
            "[ep 15][ 1000/ 1563] loss: 0.314\n",
            "[ep 15][ 1100/ 1563] loss: 0.244\n",
            "[ep 15][ 1200/ 1563] loss: 0.277\n",
            "[ep 15][ 1300/ 1563] loss: 0.689\n",
            "[ep 15][ 1400/ 1563] loss: 0.470\n",
            "[ep 15][ 1500/ 1563] loss: 0.226\n",
            "[ep 16][  100/ 1563] loss: 0.176\n",
            "[ep 16][  200/ 1563] loss: 0.524\n",
            "[ep 16][  300/ 1563] loss: 0.324\n",
            "[ep 16][  400/ 1563] loss: 0.253\n",
            "[ep 16][  500/ 1563] loss: 0.150\n",
            "[ep 16][  600/ 1563] loss: 0.285\n",
            "[ep 16][  700/ 1563] loss: 0.132\n",
            "[ep 16][  800/ 1563] loss: 0.260\n",
            "[ep 16][  900/ 1563] loss: 0.195\n",
            "[ep 16][ 1000/ 1563] loss: 0.235\n",
            "[ep 16][ 1100/ 1563] loss: 0.418\n",
            "[ep 16][ 1200/ 1563] loss: 0.377\n",
            "[ep 16][ 1300/ 1563] loss: 0.213\n",
            "[ep 16][ 1400/ 1563] loss: 0.527\n",
            "[ep 16][ 1500/ 1563] loss: 0.331\n",
            "[ep 17][  100/ 1563] loss: 0.458\n",
            "[ep 17][  200/ 1563] loss: 0.284\n",
            "[ep 17][  300/ 1563] loss: 0.160\n",
            "[ep 17][  400/ 1563] loss: 0.279\n",
            "[ep 17][  500/ 1563] loss: 0.325\n",
            "[ep 17][  600/ 1563] loss: 0.222\n",
            "[ep 17][  700/ 1563] loss: 0.133\n",
            "[ep 17][  800/ 1563] loss: 0.209\n",
            "[ep 17][  900/ 1563] loss: 0.215\n",
            "[ep 17][ 1000/ 1563] loss: 0.296\n",
            "[ep 17][ 1100/ 1563] loss: 0.364\n",
            "[ep 17][ 1200/ 1563] loss: 0.297\n",
            "[ep 17][ 1300/ 1563] loss: 0.164\n",
            "[ep 17][ 1400/ 1563] loss: 0.598\n",
            "[ep 17][ 1500/ 1563] loss: 0.547\n",
            "[ep 18][  100/ 1563] loss: 0.071\n",
            "[ep 18][  200/ 1563] loss: 0.064\n",
            "[ep 18][  300/ 1563] loss: 0.123\n",
            "[ep 18][  400/ 1563] loss: 0.244\n",
            "[ep 18][  500/ 1563] loss: 0.343\n",
            "[ep 18][  600/ 1563] loss: 0.243\n",
            "[ep 18][  700/ 1563] loss: 0.214\n",
            "[ep 18][  800/ 1563] loss: 0.259\n",
            "[ep 18][  900/ 1563] loss: 0.244\n",
            "[ep 18][ 1000/ 1563] loss: 0.281\n",
            "[ep 18][ 1100/ 1563] loss: 0.378\n",
            "[ep 18][ 1200/ 1563] loss: 0.311\n",
            "[ep 18][ 1300/ 1563] loss: 0.447\n",
            "[ep 18][ 1400/ 1563] loss: 0.294\n",
            "[ep 18][ 1500/ 1563] loss: 0.442\n",
            "[ep 19][  100/ 1563] loss: 0.101\n",
            "[ep 19][  200/ 1563] loss: 0.251\n",
            "[ep 19][  300/ 1563] loss: 0.631\n",
            "[ep 19][  400/ 1563] loss: 0.263\n",
            "[ep 19][  500/ 1563] loss: 0.793\n",
            "[ep 19][  600/ 1563] loss: 0.472\n",
            "[ep 19][  700/ 1563] loss: 0.149\n",
            "[ep 19][  800/ 1563] loss: 0.147\n",
            "[ep 19][  900/ 1563] loss: 0.401\n",
            "[ep 19][ 1000/ 1563] loss: 0.283\n",
            "[ep 19][ 1100/ 1563] loss: 0.086\n",
            "[ep 19][ 1200/ 1563] loss: 0.086\n",
            "[ep 19][ 1300/ 1563] loss: 0.033\n",
            "[ep 19][ 1400/ 1563] loss: 0.290\n",
            "[ep 19][ 1500/ 1563] loss: 0.111\n",
            "[ep 20][  100/ 1563] loss: 0.120\n",
            "[ep 20][  200/ 1563] loss: 0.313\n",
            "[ep 20][  300/ 1563] loss: 0.537\n",
            "[ep 20][  400/ 1563] loss: 0.115\n",
            "[ep 20][  500/ 1563] loss: 0.120\n",
            "[ep 20][  600/ 1563] loss: 0.272\n",
            "[ep 20][  700/ 1563] loss: 0.050\n",
            "[ep 20][  800/ 1563] loss: 0.097\n",
            "[ep 20][  900/ 1563] loss: 0.406\n",
            "[ep 20][ 1000/ 1563] loss: 0.241\n",
            "[ep 20][ 1100/ 1563] loss: 0.381\n",
            "[ep 20][ 1200/ 1563] loss: 0.042\n",
            "[ep 20][ 1300/ 1563] loss: 0.212\n",
            "[ep 20][ 1400/ 1563] loss: 0.174\n",
            "[ep 20][ 1500/ 1563] loss: 0.364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PRCaFaSEyPP",
        "outputId": "c4bc8c7c-9fcc-4589-a880-dc3364c1d5c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 60.19 %\n"
          ]
        }
      ],
      "source": [
        "# load trained model\n",
        "# model = torch.load(\"./model.pth\")\n",
        "# model.to(device)\n",
        "\n",
        "# fixed testing process\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of the network on the 10000 test images: 60.19 %"
      ],
      "metadata": {
        "id": "nJ-vWfp5pcE2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ClqMY-sxSjSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8713b130-76dc-4871-bcea-75e63f0fe6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22M\tmodel.pth\n"
          ]
        }
      ],
      "source": [
        "# model = models.mobilenet_v3_large()\n",
        "# torch.save(model, \"./model.pth\")\n",
        "\n",
        "# see size of saved model\n",
        "! du -h model.pth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TGvw3Nxya-QG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ml2022_hw2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}